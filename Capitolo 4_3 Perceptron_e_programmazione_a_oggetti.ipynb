{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron e programmazione a oggetti - inizio parte 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "path = \"C:\\\\Users\\\\ianto\\\\Desktop\\\\Corso Python per l analisi dei dati\\\\File\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path, soglia_null = 0.5, percentuale_training = 0.7):\n",
    "    iris = pd.read_csv(filepath_or_buffer=path + 'IrisDataset.csv',\n",
    "            sep = \";\", \n",
    "            header = None,\n",
    "            names = [\"rownumber\",\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"class\"],\n",
    "            skiprows = 4\n",
    "            )\n",
    "    \n",
    "    iris_working = iris.copy()\n",
    "    iris_working = iris_working[iris_working[\"class\"].isin([\"Iris setosa\",\"Iris versicolor\"])]\n",
    "    iris_working = iris_working.sample(frac=1, \n",
    "                                       random_state = 0)\n",
    "    iris_working = iris_working.drop([\"rownumber\"], \n",
    "                                     axis=1)\n",
    "    \n",
    "    \n",
    "    numero_righe = len(iris_working)\n",
    "    soglia = numero_righe * soglia_null\n",
    "    lista_colonne = list(iris_working.columns)\n",
    "    lista_colonne.remove(\"class\")\n",
    "    for colonna in lista_colonne:\n",
    "        numero_null = len(iris_working[iris_working[colonna].isna()])\n",
    "        if numero_null > soglia:\n",
    "            iris_working.drop(colonna, axis=1)     \n",
    "    \n",
    "    iris_working.loc[iris_working[\"class\"] == \"Iris setosa\", \"class\"] = 1\n",
    "    iris_working.loc[iris_working[\"class\"] == \"Iris versicolor\", \"class\"] = -1\n",
    "    \n",
    "    numero_righe_training = int(numero_righe*percentuale_training)\n",
    "    iris_training = iris_working.iloc[0:numero_righe_training].copy()\n",
    "    iris_test = iris_working.iloc[numero_righe_training:].copy()\n",
    "    \n",
    "    for colonna in lista_colonne:\n",
    "        media = iris_training[colonna].mean()\n",
    "        iris_training[colonna] = iris_training[colonna].fillna(value = media)\n",
    "        iris_test[colonna] = iris_test[colonna].fillna(value = media)\n",
    "        \n",
    "    for colonna in lista_colonne:\n",
    "        media = iris_training[colonna].mean()\n",
    "        deviazione_standard = iris_training[colonna].std()\n",
    "        iris_training[colonna] = (iris_training[colonna] - media) / deviazione_standard\n",
    "        iris_test[colonna] = (iris_test[colonna] - media) / deviazione_standard\n",
    "            \n",
    "    iris_training[\"weight\"] = 1\n",
    "    iris_test[\"weight\"] = 1\n",
    "    \n",
    "    x1 = iris_training[[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"weight\"]].values\n",
    "    y1 = iris_training[[\"class\"]].values\n",
    "\n",
    "    x2 = iris_test[[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"weight\"]].values\n",
    "    y2 = iris_test[[\"class\"]].values\n",
    "\n",
    "    return [iris, iris_training, iris_test, x1, y1, x2, y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predici(x,w):\n",
    "    x_dots_w = np.dot(x,w) \n",
    "    if x_dots_w >= 0:\n",
    "        predizione = 1\n",
    "    else:\n",
    "        predizione = -1\n",
    "    return predizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(x,y,eta=0.1,epoche=10):\n",
    "    w = np.zeros(x.shape[1])\n",
    "    iterazioni_eseguite = 0\n",
    "    lista_errori = []\n",
    "    for i1 in range(epoche): \n",
    "        iterazioni_eseguite = iterazioni_eseguite + 1\n",
    "        errori = 0\n",
    "        for i in range(x.shape[0]):\n",
    "            predizione = predici(x[i],w)\n",
    "            w = w + eta * (y[i]-predizione) * x[i]\n",
    "            if (y[i]-predizione) != 0:\n",
    "                errori = errori + 1\n",
    "        lista_errori.append(errori)\n",
    "        if(errori == 0):\n",
    "            break\n",
    "    return [w, lista_errori]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eseguiamo le due funzioni preprocessing e perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris, iris_training, iris_test, x1, y1, x2, y2 = preprocessing(path = \"C:\\\\Users\\\\ianto\\\\Desktop\\\\Corso Python per l analisi dei dati\\\\File\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, lista_errori = perceptron(x = x1, y = y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predici(x = x2[0],w = w), y2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron e programmazione a oggetti - fine parte 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron e programmazione a oggetti - inizio parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creiamo la classe perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class perceptron_class(object):\n",
    "    def __init__(self,eta = 0.1,epoche = 10):\n",
    "        self.eta = eta\n",
    "        self.epoche = epoche\n",
    "    \n",
    "    def training(self,x,y):\n",
    "        '''\n",
    "        x è un array bidimensionale di numpy contenente più righe di features\n",
    "        y è un array bidimensionale di numpy contenente più righe di classi\n",
    "        '''\n",
    "        self.w = np.zeros(x.shape[1])\n",
    "        self.listaErrori = []\n",
    "        iterazioniEseguite = 0\n",
    "        for it in range(self.epoche):\n",
    "            iterazioniEseguite = iterazioniEseguite + 1\n",
    "            errori = 0\n",
    "            for i in range(x.shape[0]):\n",
    "                predizione = self.predict(x[i])\n",
    "                self.w = self.w + self.eta * (y[i]-predizione) * x[i]\n",
    "                if (y[i]-predizione) != 0:\n",
    "                    errori = errori + 1\n",
    "            self.listaErrori.append(errori)  \n",
    "            if(errori == 0):\n",
    "                break \n",
    "    \n",
    "    def predict(self,x):\n",
    "        '''\n",
    "        x è un'array monodimensionale di numpy con una sola riga\n",
    "        '''\n",
    "        xw = np.dot(x,self.w) \n",
    "        if xw >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    def evaluate(self,x,y):\n",
    "        '''\n",
    "        x è un array bidimensionale di numpy contenente più righe di features\n",
    "        y è un array bidimensionale di numpy contenente più righe di classi\n",
    "        '''\n",
    "        self.predizioniTest = []\n",
    "        self.erroriTest = 0\n",
    "        for i in range(x.shape[0]):\n",
    "            predizione = self.predict(x[i])\n",
    "            self.predizioniTest.append(predizione)\n",
    "            if(predizione != y[i]):\n",
    "                self.erroriTest = self.erroriTest + 1 \n",
    "        self.accuratezza = 1 - self.erroriTest/len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizziamo la classe appena creata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Istanziamo l'oggetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp = perceptron_class(epoche = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizziamo l'attributo epoche valorizzato nel metodo costruttore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp.epoche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp.eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo costruttore non valorizza l'attributo w, di conseguenza la prossima istruzione genera un errore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chiamiamo il metodo training dando in input i vettori x1 e y1 creati in precedenza con il preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp.training(x1,y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto l'attributo w sarà valorizzato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lanciamo il metodo evaluate e visualizziamo l'attributo accuratezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp.evaluate(x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp.accuratezza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron e programmazione a oggetti - fine parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron e programmazione a oggetti - inizio parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creiamo la classe preprocessing_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing_iris(object):\n",
    "    \n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "     \n",
    "    def work_on_iris(self,percentuale = 0.5, percentuale_training = 0.7):\n",
    "        \n",
    "        self.import_iris(path = self.path)\n",
    "        \n",
    "        #copia, filtro e mescolamento\n",
    "        iris_working = self.iris.copy()\n",
    "        iris_working = iris_working[iris_working[\"class\"].isin([\"Iris setosa\",\"Iris versicolor\"])]\n",
    "        iris_working = iris_working.sample(frac=1,\n",
    "                                           random_state = 0)\n",
    "        iris_working = iris_working.drop([\"rownumber\"], \n",
    "                                     axis=1)\n",
    "        #calcolo colonne da eliminare\n",
    "        numero_righe = len(iris_working)\n",
    "        soglia = numero_righe*percentuale\n",
    "        lista_colonne = list(iris_working.columns)\n",
    "        lista_colonne.remove(\"class\")\n",
    "        elenco_colonne_da_eliminare = []\n",
    "        for colonna in lista_colonne:\n",
    "            numero_null = len(iris_working[iris_working[colonna].isna()])\n",
    "            if numero_null > soglia:\n",
    "                lista_colonne.remove(colonna)\n",
    "                elenco_colonne_da_eliminare.append(colonna)\n",
    "        \n",
    "        #rimozione colonne con null\n",
    "        self.rimuovi_colonne(iris_working,elenco_colonne_da_eliminare)\n",
    "        \n",
    "        \n",
    "        #codifica etichette\n",
    "        iris_working.loc[iris_working[\"class\"] == \"Iris setosa\", \"class\"] = 1\n",
    "        iris_working.loc[iris_working[\"class\"] == \"Iris versicolor\", \"class\"] = -1\n",
    "\n",
    "        #training e test\n",
    "        numero_righe_training = int(numero_righe*percentuale_training)\n",
    "        iris_training = iris_working.iloc[0:numero_righe_training].copy()\n",
    "        iris_test = iris_working.iloc[numero_righe_training:].copy()\n",
    "        \n",
    "        #calcolo medie e deviazione standard\n",
    "        elenco_medie = []    \n",
    "        elenco_deviazioni_standard = [] \n",
    "        for colonna in lista_colonne:\n",
    "            media = iris_training[colonna].mean()\n",
    "            elenco_medie.append(media)\n",
    "            deviazione_standard = iris_training[colonna].std()\n",
    "            elenco_deviazioni_standard.append(deviazione_standard)\n",
    "            \n",
    "        #valorizza null\n",
    "        self.valorizza_null(iris_training,lista_colonne,elenco_medie)\n",
    "        self.valorizza_null(iris_test,lista_colonne,elenco_medie)\n",
    "        \n",
    "        #normalizzazione\n",
    "        self.normalizzazione(iris_training, lista_colonne, elenco_medie, elenco_deviazioni_standard)\n",
    "        self.normalizzazione(iris_test, lista_colonne, elenco_medie, elenco_deviazioni_standard)\n",
    "        \n",
    "        #aggiunta colonna\n",
    "        self.aggiunta_colonna(iris_training)\n",
    "        self.aggiunta_colonna(iris_test)\n",
    "        \n",
    "        #pubblicazione attributi\n",
    "        self.lista_colonne = lista_colonne\n",
    "        self.elenco_medie = elenco_medie\n",
    "        self.elenco_deviazioni_standard = elenco_deviazioni_standard\n",
    "        self.elenco_colonne_da_eliminare = elenco_colonne_da_eliminare\n",
    "        self.iris_training = iris_training.copy()\n",
    "        self.iris_test = iris_test.copy()\n",
    "        self.x1 = iris_training[[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"weight\"]].values\n",
    "        self.y1 = iris_training[[\"class\"]].values\n",
    "        self.x2 = iris_test[[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"weight\"]].values\n",
    "        self.y2 = iris_test[[\"class\"]].values\n",
    "        \n",
    "\n",
    "    def import_iris(self,path):\n",
    "        self.iris = pd.read_csv(filepath_or_buffer= self.path + 'IrisDataset.csv',\n",
    "                sep = \";\", \n",
    "                header = None,\n",
    "                names = [\"rownumber\",\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"class\"],\n",
    "                skiprows = 4\n",
    "                )\n",
    " \n",
    "    def rimuovi_colonne(self, x, colonne):\n",
    "        '''\n",
    "        x è un dataframe\n",
    "        colonne è una lista di colonne\n",
    "        '''\n",
    "        for colonna in colonne:\n",
    "            x = x.drop(colonna, axis=1)  \n",
    "\n",
    "    def valorizza_null(self, x, colonne, medie):\n",
    "        '''\n",
    "        x è un dataframe\n",
    "        colonne è una lista di stringhe (contenenti i nomi delle colonne)\n",
    "        medie è una lista di float (contenenti le medie delle rispettive colonne)\n",
    "        '''\n",
    "        for colonna, media in zip(colonne, medie):\n",
    "            x[colonna] = x[colonna].fillna(media)\n",
    "            \n",
    "    def normalizzazione(self, x, colonne, medie, deviazioni_standard):\n",
    "        '''\n",
    "        x è un dataframe\n",
    "        colonne è una lista di stringhe (contenenti i nomi delle colonne)\n",
    "        medie è una lista di float (contenenti le medie delle rispettive colonne)\n",
    "        deviazioni_standard è una lista di float (contenenti le deviazioni standard delle rispettive colonne)\n",
    "        '''\n",
    "        for colonna, media, deviazione_standard in zip(colonne, medie, deviazioni_standard):\n",
    "            x[colonna] = (x[colonna] - media) / deviazione_standard\n",
    "    \n",
    "    def aggiunta_colonna(self, x):\n",
    "        '''\n",
    "        x è un dataframe\n",
    "        '''\n",
    "        x[\"weight\"] = 1\n",
    "        \n",
    "    def preprocessing_new_row(self,x):\n",
    "        '''\n",
    "        x è un array monodimensionale o bidimensionale di numpy contenente una sola riga di features\n",
    "        '''    \n",
    "        if type(x) is np.ndarray:\n",
    "            if type(x[0]) is np.ndarray:\n",
    "                df = pd.DataFrame(data = list(x), \n",
    "                          columns = self.lista_colonne)\n",
    "            else: \n",
    "                df = pd.DataFrame(data = [list(x)], \n",
    "                          columns = self.lista_colonne) \n",
    "        df_working = df.copy()\n",
    "        self.rimuovi_colonne(df_working, self.elenco_colonne_da_eliminare)\n",
    "        self.valorizza_null(df_working, self.lista_colonne, self.elenco_medie)\n",
    "        self.normalizzazione(df_working, self.lista_colonne, self.elenco_medie, self.elenco_deviazioni_standard)\n",
    "        self.aggiunta_colonna(df_working)\n",
    "        self.new_row = df_working.values               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inizializziamo l'oggetto pre dalla classe preprocessing_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = preprocessing_iris(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lanciamo il metodo work_on_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.work_on_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo valorizza gli attributi x1, x2, y1 e y2 con cui eseguirò l'algoritmo Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pre.x1), len(pre.x2), len(pre.y1), len(pre.y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Istanzio l'oggetto pcp relativo alla classe perceptron_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp = perceptron_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eseguo il metodo di training dando in input gli attributi x1 e y1 dell'oggetto pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp.training(pre.x1,pre.y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizzo l'attributo w generato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rivaluto l'accuratezza dando in input gli attributi x2 e y2 dell'oggetto pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp.evaluate(pre.x2,pre.y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp.accuratezza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto posso usare l'algoritmo su una nuova riga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riga = np.array([3.9,3.4, 1.5, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eseguo le operazioni di preprocessing su questa riga utilizzando metodi e attributi della classe preprocessing_iris, valorizzati in precedenza nell'oggetto pre a partire dal file Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.preprocessing_new_row(riga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizziamo come appare la nuova riga dopo il preprocessing interrogando l'attributo new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizzo il metodo predict della classe perceptron_class per predirre la classe della nuova riga. Chiamando il metodo sull'oggetto pcp, per il calcolo della predizione verrà utilizzato l'attributo pcp.w generato nelle istruzioni precedenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp.predict(pre.new_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
